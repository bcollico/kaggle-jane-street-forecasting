{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n# Initialize a list to hold samples from each file\nsamples = []\n# Load a sample from each file\nfor i in range(10):\n    file_path = f\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n    chunk = pd.read_parquet(file_path)\n    \n    # Take a sample of the data (adjust sample size as needed)\n    sample_chunk = chunk.sample(n=200000, random_state=42)  # For example, 100 rows\n    samples.append(sample_chunk)\n# Concatenate all samples into one DataFrame if needed\nsample_df = pd.concat(samples, ignore_index=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T00:45:13.285505Z","iopub.execute_input":"2024-11-11T00:45:13.285928Z","iopub.status.idle":"2024-11-11T00:46:47.707723Z","shell.execute_reply.started":"2024-11-11T00:45:13.285885Z","shell.execute_reply":"2024-11-11T00:46:47.705581Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"sample_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:17:16.072445Z","iopub.execute_input":"2024-11-10T21:17:16.072978Z","iopub.status.idle":"2024-11-10T21:17:16.110558Z","shell.execute_reply.started":"2024-11-10T21:17:16.072923Z","shell.execute_reply":"2024-11-10T21:17:16.1091Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n# Separate features and responders\nfeatures = sample_df.filter(regex='^feature_')\nresponders = sample_df.filter(regex='^responder_')\n# Convert to numpy arrays for TensorFlow\nX = features.values  # Features for input\ny = responders.values  # Responders for output\nX = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\ny = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:17:16.112741Z","iopub.execute_input":"2024-11-10T21:17:16.113402Z","iopub.status.idle":"2024-11-10T21:17:19.029436Z","shell.execute_reply.started":"2024-11-10T21:17:16.113331Z","shell.execute_reply":"2024-11-10T21:17:19.028057Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build the Autoencoder Model","metadata":{}},{"cell_type":"code","source":"# Define the number of input and output nodes\ninput_dim = X.shape[1]  # Number of features (79)\noutput_dim = y.shape[1]  # Number of responders (9)\n# Define the model\nmodel = models.Sequential([\n    layers.Input(shape=(input_dim,)),  # Input layer\n    layers.Dense(64, activation='relu'),  # Encoder\n    layers.Dense(32, activation='relu'),  # Bottleneck layer (compression)\n    layers.Dense(64, activation='relu'),  # Decoder\n    layers.Dense(output_dim, activation='linear')  # Output layer for responders\n])\nmodel.compile(optimizer='adam', loss='mse')","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:17:19.033604Z","iopub.execute_input":"2024-11-10T21:17:19.034077Z","iopub.status.idle":"2024-11-10T21:17:19.098752Z","shell.execute_reply.started":"2024-11-10T21:17:19.034029Z","shell.execute_reply":"2024-11-10T21:17:19.097454Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Autoencoder Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import LearningRateScheduler\ndef step_decay(epoch):\n    initial_lr = 0.01\n    drop = 0.5\n    epochs_drop = 5\n    lr = initial_lr * (drop ** (epoch // epochs_drop))\n    return lr\nlr_scheduler = LearningRateScheduler(step_decay)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:17:19.100159Z","iopub.execute_input":"2024-11-10T21:17:19.100583Z","iopub.status.idle":"2024-11-10T21:17:19.106868Z","shell.execute_reply.started":"2024-11-10T21:17:19.100541Z","shell.execute_reply":"2024-11-10T21:17:19.105404Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n# Define EarlyStopping\nearly_stopping = EarlyStopping(\n    monitor='val_loss',    # Monitor validation loss\n    patience=10,            # Number of epochs to wait for improvement\n    min_delta=0.001,       # Minimum change to qualify as an improvement\n    restore_best_weights=True  # Restore weights from the best epoch\n)\n\nhistory = model.fit(\n    X, y,\n    epochs=50,\n    batch_size=32,\n    validation_split=0.2,\n    callbacks=[early_stopping, lr_scheduler]\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-10T21:17:19.108678Z","iopub.execute_input":"2024-11-10T21:17:19.109203Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"/kaggle/working/model.keras\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission\n\nSee [Jane Street RMF Demo Submission](https://www.kaggle.com/code/ryanholbrook/jane-street-rmf-demo-submission) for details","metadata":{}},{"cell_type":"code","source":"import os\nimport polars as pl\nimport kaggle_evaluation.jane_street_inference_server","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\n# Assuming `model` is your trained model\n# Assuming features required by the model are named 'feature_00', 'feature_01', etc.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    global lags_\n    if lags is not None:\n        lags_ = lags\n    # Extract the features for the model input\n    feature_columns = [col for col in test.columns if col.startswith(\"feature_\")]\n    features = test.select(feature_columns).to_numpy()  # Convert to numpy array for model input\n    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n    # Generate predictions using the model\n    model_predictions = model.predict(features)\n    responder_6_predictions = model_predictions[:, 6]  # Assuming responder_6 is at index 6\n    # Create a new Polars DataFrame with row_id and responder_6 predictions\n    predictions = test.select(\"row_id\").with_columns(\n        pl.Series(\"responder_6\", responder_6_predictions)\n    )\n    # Ensure the output format and length requirements\n    if isinstance(predictions, pl.DataFrame):\n        assert predictions.columns == ['row_id', 'responder_6']\n    elif isinstance(predictions, pd.DataFrame):\n        assert (predictions.columns == ['row_id', 'responder_6']).all()\n    else:\n        raise TypeError('The predict function must return a DataFrame')\n    \n    assert len(predictions) == len(test)\n    return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}