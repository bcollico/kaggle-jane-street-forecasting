{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for the Parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from parquet_dataset.parquet_dataset import ParquetDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-11T00:45:13.285928Z",
     "iopub.status.busy": "2024-11-11T00:45:13.285505Z",
     "iopub.status.idle": "2024-11-11T00:46:47.707723Z",
     "shell.execute_reply": "2024-11-11T00:46:47.705581Z",
     "shell.execute_reply.started": "2024-11-11T00:45:13.285885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded files with rows:\n",
      "\t1944210 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\n",
      "\t2804247 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\n",
      "\t3036873 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\n",
      "\t4016784 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\n",
      "\t5022952 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\n",
      "\t5348200 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\n",
      "\t6203912 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\n",
      "\t6335560 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\n",
      "\t6140024 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\n",
      "\t6274576 : /kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\n",
      "47127338 total samples.\n"
     ]
    }
   ],
   "source": [
    "def make_train_parquet_path(i: int) -> str:\n",
    "    return f\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n",
    "# Setup the file indices to use.\n",
    "K_MAX_TRAIN_FILES: int = 10\n",
    "K_TRAIN_FILES: List[str] = [make_train_parquet_path(i) for i in range(K_MAX_TRAIN_FILES)]\n",
    "K_TEST_FILES: List[str] = [\"/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\"]\n",
    "\n",
    "train_dataset = ParquetDataset(file_paths=K_TRAIN_FILES, logging=True)\n",
    "# test_dataset = ParquetDataset(file_paths=K_TEST_FILES, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a custom sample for randomly ordering the parquet files and rows within the parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from parquet_sampler.parquet_sampler import ParquetBatchedSampler\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64,\n",
    "    num_workers=12,\n",
    "    prefetch_factor=2,\n",
    "    sampler=ParquetBatchedSampler(data_source=train_dataset)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T21:17:16.113402Z",
     "iopub.status.busy": "2024-11-10T21:17:16.112741Z",
     "iopub.status.idle": "2024-11-10T21:17:19.029436Z",
     "shell.execute_reply": "2024-11-10T21:17:19.028057Z",
     "shell.execute_reply.started": "2024-11-10T21:17:16.113331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# Separate features and responders\n",
    "features = sample_df.filter(regex='^feature_')\n",
    "responders = sample_df.filter(regex='^responder_')\n",
    "# Convert to numpy arrays for TensorFlow\n",
    "X = features.values  # Features for input\n",
    "y = responders.values  # Responders for output\n",
    "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T21:17:19.034077Z",
     "iopub.status.busy": "2024-11-10T21:17:19.033604Z",
     "iopub.status.idle": "2024-11-10T21:17:19.098752Z",
     "shell.execute_reply": "2024-11-10T21:17:19.097454Z",
     "shell.execute_reply.started": "2024-11-10T21:17:19.034029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the number of input and output nodes\n",
    "input_dim = X.shape[1]  # Number of features (79)\n",
    "output_dim = y.shape[1]  # Number of responders (9)\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),  # Input layer\n",
    "    layers.Dense(64, activation='relu'),  # Encoder\n",
    "    layers.Dense(32, activation='relu'),  # Bottleneck layer (compression)\n",
    "    layers.Dense(64, activation='relu'),  # Decoder\n",
    "    layers.Dense(output_dim, activation='linear')  # Output layer for responders\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T21:17:19.100583Z",
     "iopub.status.busy": "2024-11-10T21:17:19.100159Z",
     "iopub.status.idle": "2024-11-10T21:17:19.106868Z",
     "shell.execute_reply": "2024-11-10T21:17:19.105404Z",
     "shell.execute_reply.started": "2024-11-10T21:17:19.100541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def step_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 5\n",
    "    lr = initial_lr * (drop ** (epoch // epochs_drop))\n",
    "    return lr\n",
    "lr_scheduler = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T21:17:19.109203Z",
     "iopub.status.busy": "2024-11-10T21:17:19.108678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Define EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Monitor validation loss\n",
    "    patience=10,            # Number of epochs to wait for improvement\n",
    "    min_delta=0.001,       # Minimum change to qualify as an improvement\n",
    "    restore_best_weights=True  # Restore weights from the best epoch\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "See [Jane Street RMF Demo Submission](https://www.kaggle.com/code/ryanholbrook/jane-street-rmf-demo-submission) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "# Assuming `model` is your trained model\n",
    "# Assuming features required by the model are named 'feature_00', 'feature_01', etc.\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    # Extract the features for the model input\n",
    "    feature_columns = [col for col in test.columns if col.startswith(\"feature_\")]\n",
    "    features = test.select(feature_columns).to_numpy()  # Convert to numpy array for model input\n",
    "    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    # Generate predictions using the model\n",
    "    model_predictions = model.predict(features)\n",
    "    responder_6_predictions = model_predictions[:, 6]  # Assuming responder_6 is at index 6\n",
    "    # Create a new Polars DataFrame with row_id and responder_6 predictions\n",
    "    predictions = test.select(\"row_id\").with_columns(\n",
    "        pl.Series(\"responder_6\", responder_6_predictions)\n",
    "    )\n",
    "    # Ensure the output format and length requirements\n",
    "    if isinstance(predictions, pl.DataFrame):\n",
    "        assert predictions.columns == ['row_id', 'responder_6']\n",
    "    elif isinstance(predictions, pd.DataFrame):\n",
    "        assert (predictions.columns == ['row_id', 'responder_6']).all()\n",
    "    else:\n",
    "        raise TypeError('The predict function must return a DataFrame')\n",
    "    \n",
    "    assert len(predictions) == len(test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
